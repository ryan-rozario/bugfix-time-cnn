{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bit2c488aece8b54325bf9de11e77a9e3a5",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from hmmlearn.hmm import MultinomialHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "head=[\"id\",\"date_time\",\"flag\",\"option\"]\n",
    "\n",
    "temporal_dataset = pd.read_csv(\"./../data/FTDD/temporal_activity.csv\",header=None)\n",
    "temporal_dataset.columns=head\n",
    "temporal_dataset[\"date_time\"]=pd.to_datetime(temporal_dataset[\"date_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date_time</th>\n      <th>flag</th>\n      <th>option</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>322067</td>\n      <td>2006-01-01 04:10:56</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>322067</td>\n      <td>2007-06-06 15:24:00</td>\n      <td>W</td>\n      <td>521</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>322067</td>\n      <td>2007-06-06 15:24:00</td>\n      <td>C</td>\n      <td>521</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>322067</td>\n      <td>2007-07-04 14:35:00</td>\n      <td>Z</td>\n      <td>549</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322075</td>\n      <td>2006-01-01 06:08:45</td>\n      <td>N</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       id           date_time flag  option\n0  322067 2006-01-01 04:10:56    N       0\n1  322067 2007-06-06 15:24:00    W     521\n2  322067 2007-06-06 15:24:00    C     521\n3  322067 2007-07-04 14:35:00    Z     549\n4  322075 2006-01-01 06:08:45    N       0"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce the set\n",
    "compressed_set = temporal_dataset.groupby(['id'])['flag'].apply(lambda x: \"%s\" % ''.join(x)).reset_index()\n",
    "#i have not sorted by time but it seems to have come in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = temporal_dataset.groupby(['id'])['date_time'].apply(lambda x: max(x)).reset_index()\n",
    "t_min =temporal_dataset.groupby(['id'])['date_time'].apply(lambda x: min(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>flag</th>\n      <th>start</th>\n      <th>end</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>322067</td>\n      <td>N W C Z</td>\n      <td>2006-01-01 04:10:56</td>\n      <td>2007-07-04 14:35:00</td>\n      <td>549.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>322077</td>\n      <td>N A V C V V V Y L Z</td>\n      <td>2006-01-01 07:08:00</td>\n      <td>2006-10-31 14:56:00</td>\n      <td>303.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>322080</td>\n      <td>N C W C C Z</td>\n      <td>2006-01-01 07:52:24</td>\n      <td>2009-08-26 22:06:00</td>\n      <td>1333.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>322081</td>\n      <td>N C C Z</td>\n      <td>2006-01-01 07:54:33</td>\n      <td>2007-06-06 15:25:00</td>\n      <td>521.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>322094</td>\n      <td>N C Z</td>\n      <td>2006-01-01 12:04:36</td>\n      <td>2006-01-02 18:59:00</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       id                 flag               start                 end  \\\n0  322067              N W C Z 2006-01-01 04:10:56 2007-07-04 14:35:00   \n1  322077  N A V C V V V Y L Z 2006-01-01 07:08:00 2006-10-31 14:56:00   \n2  322080          N C W C C Z 2006-01-01 07:52:24 2009-08-26 22:06:00   \n3  322081              N C C Z 2006-01-01 07:54:33 2007-06-06 15:25:00   \n4  322094                N C Z 2006-01-01 12:04:36 2006-01-02 18:59:00   \n\n   duration  \n0     549.0  \n1     303.0  \n2    1333.0  \n3     521.0  \n4       1.0  "
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_set[\"start\"]=t_min[\"date_time\"]\n",
    "compressed_set[\"end\"]=t_max[\"date_time\"]\n",
    "compressed_set[\"duration\"]=(compressed_set[\"end\"]-compressed_set[\"start\"]).astype('timedelta64[D]')\n",
    "\n",
    "compressed_set.drop(compressed_set[compressed_set[\"duration\"]<1].index, inplace=True)\n",
    "compressed_set=compressed_set.reset_index(drop=True)\n",
    "\n",
    "compressed_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_set['flag'] = compressed_set.flag.apply(lambda x: x.strip().split())\n",
    "\n",
    "observation_dict = {'N':0,'M':1,'E':2,'A':3,'R':4,'C':5,'D':6,'V':7,'Y':8,'S':9,'H':10,'F':11,'W':12,'L':13,'P':14,'Q':15,'Z':16}\n",
    "\n",
    "compressed_set['flag'] = compressed_set.flag.apply(lambda x: list(map(lambda y: int(observation_dict[y]),x)) )\n",
    "\n",
    "\n",
    "#compressed_set = compressed_set.head(n=100)\n",
    "\n",
    "compressed_set\n",
    "\n",
    "\n",
    "\n",
    "compressed_set_long = compressed_set[compressed_set[\"duration\"] > 60]\n",
    "compressed_set_short = compressed_set[compressed_set[\"duration\"] <= 60]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(compressed_set_short)) < 0.6\n",
    "train_short = compressed_set_short[msk]\n",
    "test_short = compressed_set_short[~msk]\n",
    "msk = np.random.rand(len(compressed_set_long)) < 0.6\n",
    "train_long = compressed_set_long[msk]\n",
    "test_long = compressed_set_long[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_short.to_pickle(\"./../data/processed/train_short.pkl\")\n",
    "test_short.to_pickle(\"./../data/processed/test_short.pkl\")\n",
    "train_long.to_pickle(\"./../data/processed/train_long.pkl\")\n",
    "test_long.to_pickle(\"./../data/processed/test_long.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "17842\n12087\n18571\n12111\n"
    }
   ],
   "source": [
    "print(len(train_short))\n",
    "print(len(test_short))\n",
    "print(len(train_long))\n",
    "print(len(test_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(compressed_set.flag)\n",
    "len_sequence_long_train=[len(xi) for xi in train_long.flag]\n",
    "sequence_long_train=[[[int(x)] for x in xi]  for xi in train_long.flag]\n",
    "sequence_long_train=np.concatenate(sequence_long_train)\n",
    "\n",
    "#len(compressed_set.flag)\n",
    "len_sequence_short_train=[len(xi) for xi in train_short.flag]\n",
    "sequence_short_train=[[[int(x)] for x in xi]  for xi in train_short.flag]\n",
    "sequence_short_train=np.concatenate(sequence_short_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_states in [5]:\n",
    "    hmm_long=MultinomialHMM(n_components=n_states).fit(sequence_long_train,len_sequence_long_train)\n",
    "    hmm_short=MultinomialHMM(n_components=n_states).fit(sequence_short_train,len_sequence_short_train)\n",
    "\n",
    "    fname=\"./models/hmm_long_\"+str(n_states)+\".pkl\"\n",
    "    with open(fname, 'wb') as output:\n",
    "        pickle.dump(hmm_long, output, pickle.HIGHEST_PROTOCOL)\n",
    "    fname=\"./models/hmm_short_\"+str(n_states)+\".pkl\"\n",
    "    with open(fname, 'wb') as output:\n",
    "        pickle.dump(hmm_short, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_year in range(2006,2014):\n",
    "    start = datetime.date(year=i,month=1,day=1)\n",
    "    end = datetime.date(year=i+1,month=1,day=1)\n",
    "\n",
    "    train_long_year = train_long[(train_long['end'] > start) & (train_long['end'] < end)]\n",
    "    train_short_year = train_short[(train_short['end'] > start) & (train_short['end'] < end)]\n",
    "\n",
    "\n",
    "    #len(compressed_set.flag)\n",
    "    len_sequence_long_train=[len(xi) for xi in train_long_year.flag]\n",
    "    sequence_long_train=[[[int(x)] for x in xi]  for xi in train_long_year.flag]\n",
    "    sequence_long_train=np.concatenate(sequence_long_train)\n",
    "\n",
    "    #len(compressed_set.flag)\n",
    "    len_sequence_short_train=[len(xi) for xi in train_short_year.flag]\n",
    "    sequence_short_train=[[[int(x)] for x in xi]  for xi in train_short_year.flag]\n",
    "    sequence_short_train=np.concatenate(sequence_short_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for n_states in [5]:\n",
    "\n",
    "        hmm_long=MultinomialHMM(n_components=n_states).fit(sequence_long_train,len_sequence_long_train)\n",
    "        hmm_short=MultinomialHMM(n_components=n_states).fit(sequence_short_train,len_sequence_short_train)\n",
    "\n",
    "        fname=\"./models/hmm_long_\"+str(n_year)+\"_\"+str(n_states)+\".pkl\"\n",
    "        with open(fname, 'wb') as output:\n",
    "            pickle.dump(hmm_long, output, pickle.HIGHEST_PROTOCOL)\n",
    "        fname=\"./models/hmm_short_\"+str(n_year)+\"_\"+str(n_states)+\".pkl\"\n",
    "        with open(fname, 'wb') as output:\n",
    "            pickle.dump(hmm_short, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}